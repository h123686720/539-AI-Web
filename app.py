import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
from collections import Counter
import os

st.set_page_config(page_title="539 AI æ™ºèƒ½ç ”ç™¼ç³»çµ±", layout="centered")

# --- æ ¸å¿ƒçˆ¬èŸ²åŠŸèƒ½ ---
def get_geggg_data():
    url = "https://539.geggg.com/page2.php"
    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        response = requests.get(url, headers=headers, timeout=15)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # é‡å° geggg.com çš„çµæ§‹ç²¾æº–æŠ“å–
        all_rows = []
        # æŠ“å–è¡¨æ ¼ä¸­æ‰€æœ‰çš„è¡Œ
        rows = soup.find_all('tr')
        for row in rows:
            cols = row.find_all('td')
            # geggg çš„çµæ§‹é€šå¸¸æ˜¯ï¼šæ—¥æœŸåœ¨ç¬¬1æ¬„ï¼Œè™Ÿç¢¼åœ¨ç¬¬2æ¬„
            if len(cols) >= 2:
                raw_date = cols[0].get_text(strip=True)
                raw_nums = cols[1].get_text(strip=True)
                
                # ç°¡å–®æ ¼å¼åŒ–æ—¥æœŸ
                date = raw_date[:10].replace("-", "/")
                # æå–å‡º5å€‹æ•¸å­— (ä¾‹å¦‚ 01 05 33 36 38)
                nums = [n for n in raw_nums.split() if n.isdigit() and len(n) == 2]
                
                if len(nums) == 5:
                    all_rows.append([date] + nums)
        
        if all_rows:
            df = pd.DataFrame(all_rows, columns=['date', 'n1', 'n2', 'n3', 'n4', 'n5'])
            df.to_csv('history539.csv', index=False, encoding='utf-8-sig')
            return df
        return None
    except Exception as e:
        st.error(f"æŠ“å–ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

# --- UI ä»‹é¢ ---
st.markdown("<h1 style='text-align: center;'>ğŸ”® 539 AI æ™ºèƒ½ç ”ç™¼ç³»çµ±</h1>", unsafe_allow_html=True)

# åŒæ­¥æŒ‰éˆ•
if st.button("ğŸ”„ é»æ“ŠåŒæ­¥æœ€æ–°é–‹çæ•¸æ“š (å¾ geggg.com)"):
    with st.spinner("æ­£åœ¨æŠ“å–ä¸­..."):
        df = get_geggg_data()
        if df is not None:
            st.success("âœ… æ•¸æ“šæ›´æ–°æˆåŠŸï¼")
            st.rerun() # é‡æ–°æ•´ç†é é¢ä»¥é¡¯ç¤ºæ–°æ•¸æ“š
        else:
            st.error("âŒ ç„¡æ³•å–å¾—æ•¸æ“šï¼Œè«‹ç¢ºèªç¶²ç«™æ˜¯å¦æ­£å¸¸ã€‚")

st.divider()

# --- è®€å–èˆ‡é‚è¼¯åˆ†æ (åŠ å…¥ç©ºæª”æ¡ˆä¿è­·) ---
if os.path.exists('history539.csv'):
    try:
        df_display = pd.read_csv('history539.csv')
        if not df_display.empty:
            st.write(f"ğŸ“Š ç›®å‰åˆ†ææœŸæ•¸ï¼š{len(df_display)} æœŸ")
            latest = df_display.iloc[0]
            st.info(f"ğŸ“… æœ€æ–°é–‹çï¼š{latest['date']} \n\n ğŸ° çè™Ÿï¼š{latest['n1']:02}, {latest['n2']:02}, {latest['n3']:02}, {latest['n4']:02}, {latest['n5']:02}")
            
            # AI æ¨è–¦é‚è¼¯
            all_nums = df_display.iloc[:, 1:6].values.flatten().astype(int)
            counts = Counter(all_nums)
            # å–å¾—æœ€å¸¸å‡ºç¾çš„è™Ÿç¢¼ä½œç‚ºç¤ºç¯„
            recommend = [n for n, c in counts.most_common(7)]
            
            st.subheader("ğŸ’ ä»Šæ—¥ AI æ¨è–¦ã€å°ˆè»Šã€‘")
            st.markdown(f"### <font color='#ff4b4b'>{recommend[0]:02d} , {recommend[1]:02d}</font>", unsafe_allow_html=True)
            
            st.subheader("ğŸ”¥ ä»Šæ—¥ AI æ¨è–¦ã€é€£ç¢°ã€‘")
            st.markdown(f"### {' , '.join([f'{x:02d}' for x in recommend[2:7]])}")
        else:
            st.warning("âš ï¸ æª”æ¡ˆå…§å®¹ç‚ºç©ºï¼Œè«‹é»æ“Šä¸Šæ–¹æŒ‰éˆ•åŒæ­¥æ•¸æ“šã€‚")
    except:
        st.warning("âš ï¸ æª”æ¡ˆè®€å–å¤±æ•—ï¼Œè«‹é‡æ–°é»æ“ŠåŒæ­¥æŒ‰éˆ•ã€‚")
else:
    st.warning("ğŸ‘‹ æ­¡è¿ï¼è«‹å…ˆé»æ“Šä¸Šæ–¹æŒ‰éˆ•åŒæ­¥ã€æ¨‚é€é è¨€å®¶ã€çš„æ­·å²æ•¸æ“šã€‚")
