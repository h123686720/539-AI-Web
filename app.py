import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
from collections import Counter
import os

st.set_page_config(page_title="539 AI æ™ºèƒ½ç³»çµ±", layout="centered")

# --- å¼·åŒ–ç‰ˆçˆ¬èŸ²åŠŸèƒ½ ---
def get_data_from_web(pages=5):
    url = "https://539.geggg.com/page2.php"
    headers = {'User-Agent': 'Mozilla/5.0'}
    rows_list = []
    try:
        for p in range(1, pages + 1):
            p_url = f"{url}?page={p}"
            res = requests.get(p_url, headers=headers, timeout=10)
            res.encoding = 'utf-8'
            soup = BeautifulSoup(res.text, 'html.parser')
            for row in soup.find_all('tr'):
                cols = row.find_all('td')
                if len(cols) >= 2:
                    dt = cols[0].get_text(strip=True)[:10].replace("-", "/")
                    nums = [n for n in cols[1].get_text(strip=True).split() if n.isdigit() and len(n)==2]
                    if len(nums) == 5:
                        rows_list.append([dt] + nums)
        return rows_list
    except:
        return None

st.markdown("<h1 style='text-align: center;'>ğŸ”® 539 AI æ™ºèƒ½ç ”ç™¼ç³»çµ±</h1>", unsafe_allow_html=True)

# --- åŠŸèƒ½å€å¡Šï¼šåŒæ­¥èˆ‡æ‰‹å‹•è£œè™Ÿ ---
with st.expander("ğŸ› ï¸ æ•¸æ“šç®¡ç†å·¥å…· (ç¶²ç«™æ²’æ›´æ–°æ™‚é»æ­¤)"):
    c1, c2 = st.columns(2)
    if c1.button("ğŸ”„ åŒæ­¥æœ€æ–°æ•¸æ“š"):
        with st.spinner("åŒæ­¥ä¸­..."):
            new_rows = get_data_from_web(5)
            if new_rows:
                new_df = pd.DataFrame(new_rows, columns=['date','n1','n2','n3','n4','n5'])
                if os.path.exists('history539.csv'):
                    old_df = pd.read_csv('history539.csv')
                    new_df = pd.concat([new_df, old_df]).drop_duplicates(subset=['date'])
                new_df.to_csv('history539.csv', index=False, encoding='utf-8-sig')
                st.success("åŒæ­¥å®Œæˆï¼")
                st.rerun()

    st.write("---")
    st.write("ğŸ“ æ‰‹å‹•æ–°å¢æ˜¨å¤©è™Ÿç¢¼ (å¦‚ç¶²ç«™å°šæœªæ›´æ–°)")
    in_date = st.text_input("æ—¥æœŸ", value="2026/01/21")
    in_nums = st.text_input("è™Ÿç¢¼ (ç©ºæ ¼éš”é–‹)", placeholder="ä¾‹å¦‚: 05 12 18 24 37")
    if st.button("â• ç¢ºèªæ‰‹å‹•æ–°å¢"):
        nums_list = in_nums.split()
        if len(nums_list) == 5:
            new_entry = pd.DataFrame([[in_date] + nums_list], columns=['date','n1','n2','n3','n4','n5'])
            if os.path.exists('history539.csv'):
                old_df = pd.read_csv('history539.csv')
                final_df = pd.concat([new_entry, old_df]).drop_duplicates(subset=['date'])
            else:
                final_df = new_entry
            final_df.to_csv('history539.csv', index=False, encoding='utf-8-sig')
            st.success("æ‰‹å‹•è£œè™ŸæˆåŠŸï¼")
            st.rerun()
        else:
            st.error("è«‹è¼¸å…¥æ­£ç¢ºçš„5å€‹è™Ÿç¢¼")

st.divider()

# --- é¡¯ç¤ºèˆ‡åˆ†æ ---
if os.path.exists('history539.csv'):
    df = pd.read_csv('history539.csv').sort_values(by='date', ascending=False)
    st.write(f"ğŸ“Š ç›®å‰åˆ†ææœŸæ•¸ï¼š**{len(df)}** æœŸ")
    l = df.iloc[0]
    st.info(f"ğŸ“… æœ€æ–°çè™Ÿ ({l['date']})ï¼š{l['n1']:02d}, {l['n2']:02d}, {l['n3']:02d}, {l['n4']:02d}, {l['n5']:02d}")
    
    # æ¬Šé‡åˆ†æé‚è¼¯
    all_n = df.iloc[:, 1:6].values.flatten().astype(int)
    counts = Counter(all_n)
    scores = {i: counts.get(i,0)*5 for i in range(1,40)}
    # å¢åŠ æ‚¨åå¥½çš„å°¾æ•¸åŠ æ¬Š
    for i in range(1,40):
        if i % 10 in [2, 8, 9]: scores[i] += 15
    
    rec = [x[0] for x in sorted(scores.items(), key=lambda x:x[1], reverse=True)]
    
    st.subheader("ğŸ’ ä»Šæ—¥ AI æ¨è–¦ã€å°ˆè»Šã€‘")
    st.markdown(f"## <font color='#ff4b4b'>{rec[0]:02d} , {rec[1]:02d}</font>", unsafe_allow_html=True)
    st.subheader("ğŸ”¥ ä»Šæ—¥ AI æ¨è–¦ã€é€£ç¢°ã€‘")
    st.markdown(f"### {' , '.join([f'{x:02d}' for x in rec[2:7]])}")
else:
    st.warning("è«‹å…ˆä½¿ç”¨ä¸Šæ–¹å·¥å…·åŒæ­¥æ•¸æ“šã€‚")
